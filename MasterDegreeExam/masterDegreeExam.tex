\documentclass[12pt]{article}
\usepackage[T1,T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[bulgarian]{babel}
\usepackage{amssymb,amsmath}
\usepackage{amsthm}
\usepackage{pgfplots} 
\usepackage{tikz}
\usetikzlibrary{patterns}
\numberwithin{equation}{section}
\newtheorem{theorem}{Теорема}
\newtheorem{definition}{Дефиниция}
\newtheorem{feature}{Свойство}
\newtheorem{corollary}{Следствие}

\numberwithin{theorem}{section}
\numberwithin{definition}{section}
\numberwithin{corollary}{section}
\begin{document}

\section{Интерполационна формула на Лагранж}
\paragraph{Постановка на задачата\\}
Нека $x_1,x_2,...,x_n$ са различни точки и $y_1,y_2,...,y_n$ са дадени
реални числа.
\par
Да се построи алгебричен полином $P(x)$ от степен $\leq n$, който удовлетворява следните условия:\\
\begin{equation} \label{e1}
        P(x_k) = y_k,\hspace{12pt} k=0,\dotso,n 
\end{equation}
\par
С други думи, при дадените $n+1$ точки $\{(x_k,y_k)\}_{k=0}^n$ в равнината, да се построи полином $P$ от степен $n$, чиято гафика минава през дадените точки $\{(x_k,y_k)\}_{k=0}^n$.
\par
Да отбележим най-напред, че ако изобщо съществува решение на \ref{e1}, то трябва да е единствено.
\par
Допускаме, че съществуват два полинома $P$ и $Q$ от степен $n$, които удовлетворяват \ref{e1}, тогава разликата
\[
R(x) = P(x) - Q(x)
\]
ще бъде полином от степен $\leq n$ и освен това 
\[
R(x_k) = P(x_k) - Q(x_k) = y_k - y_k = 0,\hspace{12pt}k=0,\dotso,n
\]
Следователно R е полином от степен $n$, който се анулира в $n+1$ точки. Тогава от основната теорема на алгебрата $R(x)$ е тъждествено равен на 0. Следователно $P\equiv Q$.
\par
Съществуването и единствеността на решението на \ref{e1} се виждат и по следния начин.
\par
Да напишем $P$ в общ вид.
\[
P(x) = a_0x^n + a_1x^{n-1} + \dotso + a_{n-1}x + a_n
\]
\par
Тогава \ref{e1} добива следния вид:
\begin{align*}
a_0x_0^n + \dotso + a_n &= y_0\\
a_0x_1^n + \dotso + a_n &= y_1\\
\dotso\\
a_0x_n^n + \dotso + a_n &= y_n\\
\end{align*}
\par
Това е система от $n+1$ линейни уравнения по отношение на $(a_0,a_1,\dotso,a_n)$. Детерминантата ѝ
\[
V(x_0,\dotso,x_n) = det
\begin{vmatrix} 
&x_0^n &x_0^{n-1} &\dotso &x_0 &1\\
&x_1^n &x_1^{n-1} &\dotso &x_1 &1\\
&\dotso&\dotso&\dotso&\dotso&\dotso \\
&x_n^n &x_n^{n-1}&\dotso &x_n &1 
\end{vmatrix}
\]
е детерминантата на Вандермонд. От линейната алгебра знаем, че детерминантата на Вандермонд съответстваща на точките $x_0, \dotso , x_n$ е различна от ), ако $x_i \neq x_j$, при $i \neq j$. Тъй като точките $x_0, \dotso , x_n$ в (1) са различни по условие, $V(x_0, \dotso, x_n \neq 0$ и следователно системата, а оттук и задачата има единствено решение (тоест системата е определена ???).
\paragraph{Извеждане на формулата}
\par
При фиксирано $k$ да се намери полинома $l_{nk}(x)\in \pi_n$, който удовлетворява условията:
\begin{enumerate}
    \item $l_{nk}(x_i) = 0$, за $i = 0, \dotso, n$ и $i \neq k$
    \item $l_{nk}(x_i) = 1$, за $i = k$
\end{enumerate} 
\par
От 1. следва, че точките $x_0, \dotso, x_{k-1}, x_{k+1}, \dotso x_n$ са нули на полинома $l_{nk}$. От $l_{nk} \in \pi_n$ следва, че $x_0, \dotso, x_{k-1}, x_{k+1}, \dotso x_n$ са всичките нули. Тогава $l_{nk}$ може да се запише във вида:
\[
l_{nk}(x) = A(x - x_0)\dotso(x - x_{k-1})(x - x_{k+1})\dotso(x-x_n),
\]
където $A$ е някакво число. $A$ се определя от 2..
\[
1 = l_{nk}(x_k) = A(x_k - x_0)\dotso(x_k - x_{k-1})(x_k - x_{k+1})\dotso(x_k - x_n)
\]
\par
Следователно:
\[
A = \frac{1}{\displaystyle \prod_{i=0,i\neq k}^{n}(x_k-x_i)}.
\]
\par
Тогава
\begin{align}\label{e2}
\begin{split}
l_{nk}(x) &= \frac{(x - x_0)\dotso(x - x_{k-1})(x - x_{k+1})\dotso (x - x_n)}
{(x_k - x_0)\dotso(x_k - x_{k-1})(x_k - x_{k+1})\dotso(x - x_n)}\\ &= 
\displaystyle \prod_{i = 0, i \neq k}^n\left(\frac{x-x_i}{x_k - x_i}\right).
\end{split}
\end{align}
\par
Полиномите $\{l_{nk}\}_{k = 0}^n$ се наричат базисни полиноми на Лагранж. С тяхна помощ може лесно да се построи $P$.
\par
Ще покажем, че решението $P(x)$ на \ref{e1} се дава с 
\begin{equation}\label{e3}
P(x) = \displaystyle\sum_{k = 0}^ny_kL_{nk}(x)
\end{equation}
\par
По построение
\[
l_{nk}(x_i) = \delta_{ki} = 
\begin{cases}
1, &k = i\\
0, &k \neq i
\end{cases}
\]
\par
Тогава
\[
P(x_i) = \displaystyle\sum_{k = 0}^ny_kl_{nk}(x_i) = y_il_{ni}(x_i) = y_i1 = y_i,
\]
за всяко $i = 0,\dotso,n$. Oт това, че полиномът \ref{e3} е от $\pi_n (l_{nk}\in\pi_n)$ и удовлетворява \ref{e1}, следва,че $P(x)$ даден в \ref{e3} е решение на интерполационната задача.
\par
Най-често $\{y_k\}_{k=0}^n$ са стойностите на някаква функция $f(x)$ в точките $x_0, x_1,\dotso, x_n$, тоест
\[
y_k = f(x_k),\hspace{12pt}, k = 0, \dotso, n.
\]
\par
В такъв случай
\[
P(x_k) = f(x_k),\hspace{12pt}, k = 0, \dotso, n
\]
се бележи с $L_n(f;x)$ и се нарича интерполационен полином на Лагранж за функцията $f$ с възли $x_0, \dotso, x_n$. Казваме още, че $L_n(f;x)$ интерполира $f(x)$ в точките $(x_0, \dotso, x_n)$.
\par
И така доказахме следната теорема
\begin{theorem}\label{T1}
Нека $x_0 < \dotso < x_n$ и $f(x)$ е определена в тези точки. Тогава съществува единствен полином от $\pi_n$, който интерполира $f$ в $x_0, \dotso, x_n$. Този полином се представя чрез формулата:
\begin{equation}\label{e4}
L_n(f;x) = \displaystyle\sum_{k=0}^nf(x_k)
            \displaystyle\prod_{i = 0, i \neq k}^n\frac{x-x_i}{x_k-x_i}
\end{equation}
\end{theorem}
\par
Твърдението следва веднага от \ref{e3} като вземем предвид, че съгласно \ref{e2}
\[
l_{nk}(x) = \displaystyle\prod_{i = 0, i \neq k}^n
            \frac{x-x_i}{x_k-x_i}
\]
\par
Формула \ref{e4} се нарича интерполационна формула на Лагранж.
\par
Понякога ще използваме по-кратък запис за $l_{nk}$.
\[
w'(x_k) = (x_k - x_0)\dotso(x_k - x_{k-1})(x_k - x_{k+1})\dotso(x_k - x_n),
\]
където
\[
w(x) = (x-x_0)\dotso(x-x_n).
\]
\par
Тогава
\[
l_{nk} = \frac{w(x)}{(x-x_k)w'(x_k)}
\]
и
\[
L_n(f;x) = \displaystyle\sum_{k=0}^nf(x_k)
            \frac{w(x)}{(x-x_k)w'(x_k)}.
\]
\paragraph{Оценка на грешката}
Обикновено интерполационнния полином $L_n(f;x)$ се използва за приближаване на по сложна функция $f(x)$. Тогава възникава въпроса : Какво можем да кажем за разликата:
\[
R_n(f;x) = f(x) -L_n(f;x)
\]
в някакво предварително избрано $x$?
\par
Да обърнем внимание, че полиномът $L_n(f;x)$ беше построен само въз основа на точките $\{x_k,f(x_k)\}_{k=0}^n$. Но през тези същите точки минават графиките на безброй други непрекъснати функции $g(x)$ и очевидно за тях имаме $L_n(g;x) \equiv L_n(f;x)$. При това за всяко $c > 0$ можем да построим непрекъсната функция $g$ от разглеждания клас - такава, че $g(x) - L_n(f;x) = c$. Следователно грешката може да бъде произволно голяма ако нищо не знаем за формулата освен това, че е непрекъсната. За това в следващата теорема се налага едно допълнително условие за гладкост на $f$.
\begin{theorem} \label{T2}
Нека $[a,b]$ е даден краен интервал и $x_0, \dotso, x_n$ са различни точки в него. Нека функцията $f(x)$ има непрекъсната $(n+1)$-ва производна в $[a,b]$. Тогава $\forall x \in [a,b] \exists \xi \in [a,b] :$
\[
f(x)-L_n(f;x) = \frac{f^{(n+1)}(\xi)}{(n+1)!}(x-x_0)\dotso(x-x_n).
\]
\end{theorem}
\begin{proof}
\par
Образуваме помощната функция 
\[
F(t) = f(t) - L_n(f;t) - c(t-x_0)\dotso(t-x_n),
\]
където $c$ е параметър. $F(t)$ се анулира в точките $x_0, \dotso, x_n$ при всеки избор на $c$.
\[
F(x_k) = f(x_k) - L_n(f;k) - c.0 = f(x_k) - f(x_k) = 0.
\]
\par
Избираме $c$ така, че $F(t)$ да се анулира и при $t=x$. От равенството
\[
f(x) - L_n(f;x) - c(x-x_0)\dotso(x-x_n) = 0
\]
определяме
\begin{equation}\label{e5}
c = \frac{R_n(f;x)}{(x-x_0)\dotso(x-x_n)}.
\end{equation}
\par
И така при този избор на $c$ функцията $F(t)$ има поне $n+2$ нули. Това са точките $x, x_0, \dotso, x_n$. По теоремата на Рол $F'(t)$ ще има поне $n+1$ нули, които лежат в интервала $[a,b], F''(t)$ ще има поне $n$ нули и тн. $F^{(n+1)}(t)$ ще има поне една нула, която лежи в $[a,b]$. Да я означим с $\xi$. Имаме $F^{(n+1)}(\xi) = 0$. От друга страна,
\begin{align*}
F^{(n+1)}(\xi) &= f^{(n+1)}(\xi) - L_n(f;\xi) - c(n+1)! =\\&= 
f^{(n+1)}(\xi) - c(n+1)!.
\end{align*}
\par
Следователно
\[
c = \frac{f^{(n+1)}(\xi)}{(n+1)!}.
\]
\par
Като сравним това равенство с \ref{e5} получаваме:
\[
R_n(f;x) = \frac{f^{(n+1)}(\xi)}{(n+1)!}(x-x_0)\dotso(x-x_n).
\]
\par
Теоремата е доказана.
\end{proof}
\newpage
\section{Разделени разлики. Интерполационна формула на Нютон.}
\begin{definition}
Нека $x_0, \dotso, x_n$ са дадени различни точки. Разделената разлика на функция $f$ в точките $x_0, \dotso, x_n$ се бележи с $f[x_0, \dotso, x_n]$ и се определя индуктивно със следната рекурентна връзка.
\begin{equation}\label{e6}
f[x_0, \dotso, x_n] = \frac{f[x_1, \dotso, x_n] - f[x_0, \dotso, x_{n-1}]}{x_n - x_0},\hspace{12pt}n = 1, \dotso, \infty
\end{equation}
, като приемаме, че $f[x_i] = f(x_i)$
\end{definition}
\par
Съществува връзка между интерполационния полином на Лагранж с възли $x_0, \dotso, x_n$ и разделената разлика $f[x_0, \dotso, x_n]$. Тя се разкрива в следната теорема.
\begin{theorem} \label{Th1}
Разделената разлика $f[x_0, \dotso, x_n]$ съвпада с коефициента пред $x^n$ в интерполационния полином на Лагранж $L_n(f;x)$ за функцията $f$ с възли в същите точки $x_0, \dotso, x_n$.
\end{theorem}
\begin{proof}
Доказателството се извършва по индукция относно броя на точките.
База: $n = 1 - x_0,x_1$
\begin{align*}
L_1(f;x) &= f(x_0)\frac{x - x_1}{x_0 - x_1} + f(x_1)\frac{x - x_0}{x_1 - x_0} =\\ &= \frac{f(x_1) - f(x_0)}{x_1 - x_0}(x - x_0) + f(x_0) =\\ &= f[x_0, x_1](x - x_0) + f(x_0).
\end{align*}
\par
Следователно коефициентът пред $x$ в $L_1(f;x)$ е равен на разделената разлика $f[x_0, x_1]$. 
\par
Да допуснем, че теоремата е изпълнена за произволно $n$. Ще докажем, че е изпълнена и за $n+1$ точки.
\par
Нека $x_0, \dotso, x_n$ са произволни $n+1$ различни точки и нека\\
\hspace{20pt} $p(x) \in \pi_{n-1}$ интерполира $f$ в $x_1, \dotso, x_n$
\hspace{20pt} $q(x) \in \pi_{n-1}$ интерполира $f$ в $x_0, \dotso, x_{n-1}$
\par
Разглеждаме полинома 
\[
r(x) = \frac{(x - x_0)p(x) - (x - x_n)q(x)}{x_n - x_0}
\]
\par
От $p$ и $q \in \pi_{n-1}$, следва, че $r$ е алгебричен полином от степен $\leq n$. Освен това при $i\in(1,n-1)$,
\[
r(x_i) = \frac{(x_i - x_0)f(x_i) - (x_i - x_n)f(x_i)}{x_n - x_0} = f(x_i)
\]
\par
При $i = 0$ и $i = n$ имаме
\begin{align*}
r(x_0) &= -\frac{x_0 - x_n}{x_n - x_0}q(x_0) &= f(x_0)\\
r(x_n) &= \frac{x_n - x_0}{x_n - x_0}p(x_n) &= f(x_n)
\end{align*}
\par
Следователно $r \in \pi_n$ и $r$ интерполира $f(x)$ в точките $x_0, \dotso, x_n$. От единствеността на интерполационния полином на Лагранж следва, че:
\[
r(x) \equiv L_n(f;x)
\]
\par
Следователно коефициентът пред $x^n$ в $L_n(f;x)$ е равен на коефициентът пред $x^n$ в $r(x)$.
\par
Нека $\alpha$ и $\beta$ са коефициентите пред $x^{n-1}$ съответно в $p(x)$ и $q(x)$. Тогава от формулата за $r(x)$ се вижда, че коефициентът $D$ пред $x^n$ в $r(x)$ е равен на $\frac{\alpha - \beta}{x_n - x_0}$.
\par
Но съгласно индукционното предположение 
\begin{align*}
\alpha &= f[x_1, \dotso, x_n]\\
\beta &= f[x_0, \dotso, x_{n-1}]
\end{align*}
\par
Следователно
\begin{align*}
\begin{split}
D &= \frac{f[x_1, \dotso, x_n] - f[x_0, \dotso, x_{n-1}]}{x_n - x_0} =\\
&= f[x_0, \dotso, x_n]
\end{split}
\end{align*}
\par
Последното равенство следва от рекурентна връзка \ref{e6}. Следователно индукцията е завършена и теоремата е доказана.
\end{proof}
\par
От теорема \ref{Th1} следват редица интересни свойства на разделената разлика.
\par
От записа
\[
f[x_0, x_1] = f(x_0)\frac{1}{x_0 - x_1} + f(x_1)\frac{1}{x_1-x_0}
\]
се виждам, че разделената разлика $f[x_0,x_1]$ се представя като линейна комбинация на стойностите на функцията $f$ в $x_0, x_1$. Тогава от \ref{e6} следва, че $f[x_0, \dotso, x_n]$ се представя като линейна комбинация на $f$ в $x_0, \dotso, x_n$.
\par
За намиране на коефициентите пред $f(x_0), \dotso, f(x_n)$ ще използваме теорема \ref{Th1}.
\par
От формулата на Лагранж
\begin{align*}
\begin{split}
L_n(f;x) &= \displaystyle\sum_{k=0}^nf(x_k)
            \displaystyle\prod_{i=0,i \neq k}^n\frac{x-x_i}{x_0 - x_i} =\\
        &=  \displaystyle\sum_{k=0}^n
            \frac{f(x_k)}{\displaystyle\prod_{i=0, i \neq k}^nx_k - x_i}
            \frac{w(x)}{x-x_k},
\end{split}
\end{align*}
където $w(x) = (x - x_0)\dotso (x - x_n)$.
\par
От последното равенство се вижда, че коефициентът пред $x^n$ в $L_n(f;x)$ е равен на:
\[
\displaystyle\sum_{k=0}^n\frac{f(x_k)}{\displaystyle\prod_{i=0,i\neq k}^n(x_k-x_i)}
\]
\par
Следователно съгласно теорема \ref{Th1}
\begin{equation} \label{e2.2}
f[x_0, \dotso, x_n] = \displaystyle\sum_{k=0}^n\frac{f(x_k)}{\displaystyle\prod_{i=0,i\neq k}^n(x_k-x_i)}
\end{equation}
\par
Това е търсеното явно представяне на разделената разлика чрез стойностите на $f$ в точките $x_0, \dotso, x_n$.
\par
Като използваме
\[
w'(x_k) = \displaystyle\prod_{i=0, i\neq k}^n(x_k-x_i)
\]
можем да запишем \ref{e2.2} като
\[
f[x_0,\dotso, x_n] = \displaystyle\sum_{k=0}^n
                    \frac{f(x_k)}{w'(x_k)}.
\]
\par
от \ref{e2.2} се вижда, че разделената разлика е един линеен функционал, тоест за всеки две функции $f,g$ и число $c$ е в сила формулата
\[
(f+cg)[x_0,\dotso, x_n] = f[x_0, \dotso, x_n] + cg[x_0, \dotso, x_n],
\]
за всяко разместване (пермутация) $(i_0, \dotso, i_n)$ на индексите $(0,\dotso, n)$.
\par
Ще докажем, че ако
\begin{align*}
f(x) &= a_0x^n + a_1x^{n-1}+\dotso+a_{n-1}x+a_n, \text{то}\\
f[x_0,\dotso, x^n] &= a_0
\end{align*}
\par
С други думи разделената разлика в $n+1$ точки на полиом от степен $n$ е равна на коефициента пред $x^n$. Това твърдение следва веднага от факта, че ако $f\in \pi_n$, то $f$ съвпада с интерполационния си полином на Лагранж с $n+1$ точки. Тогава
\begin{align*}
\begin{split}
f[x_0, \dotso, x_n] &= \text{коефициента пред } x^n \text{ в } L_n(f;x)\\
                    &= \text{коефициента пред } x^n \text{ в } f(x)\\
                    &= a_0
\end{split}
\end{align*}
\par
Един важен частен случай на това твърдение е следното свойство:
\begin{feature}
Ако $f\in\pi_{n-1}$, то $f[x_0, \dotso, x_n] = 0$
\end{feature}
\par
Следователно разделената разлика в $n+1$ точки винаги анулира всички полиноми от степен по-малка или равна на $n-1$.
\par
Сега вече сме готови да изведем формулата на Нютон за интерполационни полиноми. За целта разглеждаме разликата:
\[
L_{k+1}(f;x) - L_k(f;x),
\]
където $L_{k+1}(f;x)$ интерполира $f$ в $x_0,\dotso,x_{k+1}$, а $L_k(f;x)$ интерполира $f$ в $x_0,\dotso, x_k$. Ясно е, че $L_{k+1}(f;x) - L_k(f;x)\in\pi_{k+1}$. Освен това
\[
L_{k+1}(f;x) - L_k(f;x) = f(x_i) - f(x_i) = 0, \text{за} i = 0,\dotso,k.
\]
\par
Следователно $x_0,\dotso,x_k$ са всичките нули на полинома $L_{k+1}(f;x) - L_k(f;x)$. Тогава той може да се запише във вида:
\begin{equation} \label{e2.3}
L_{k+1}(f;x) - L_k(f;x) = A(x-x_0)\dotso(x-x_k),
\end{equation}
където $A$ е константа. За да намерим $A$ нека сравним коефициентите пред $x^{k+1}$ в \ref{e2.3}.
\par
Съгласно теорема \ref{Th1} коефициента пред $x^{k+1}$ в $L_{k+1}(f;x)$ е равен на разделената разлика $f[x_0,\dotso, x_{k+1}]$. Следователно 
\[
A = f[x_0,\dotso,x_k+1]
\]
и следователно от \ref{e2.3}
\begin{equation} \label{e2.4}
L_{k+1}(f;x) = L_k(f;x) + f[x_0,\dotso,x_{k+1}](x-x_0)\dotso(x-x_k)
\end{equation}
\par
Нека приложим \ref{e2.4} за $k=n-1,n-3,\dotso,2,1,0$. Получаваме следния явен израз за интерполационния полином на Лагранж.
\begin{align*}
\begin{split}
L_n(f;x) &= f(x_0) + f[x_0,x_1](x-x_0) +\\&+f[x_0,x_1,x_2](x-x_0)(x-x_1)+\dotso+\\&+f[x_0,\dotso,x_n](x-x_0)\dotso(x-x_{n-1})
\end{split}
\end{align*}
\par
Това е интерполационната формула на Нютон. Понякога ще я записваме съкратено така
\begin{equation}\label{e2.5}
L_n(f;x) = \displaystyle\sum_{k=0}^nf[x_0,\dotso,x_k](x-x_0)\dotso(x-x_{k-1}),
\end{equation}
като приемаме, че $(x-x_0)\dotso(x-x_{k-1}) = 1$ при $k=0$.
\paragraph{Представяне на грешката}
\par
Сега ще изведем един израз за остатъка на $f$ като използваме разделени разлики.
\par
Нека $x$ е произволна фиксирана точка различна от $x_0,\dotso, x_n$. Да означим с $L_{n+1}(f;t)$ полинома, който интерполира $f$ в точките $x_0,\dotso, x_n$ и $x$. Нека $L_n(f;t)$ интерполира $f$ в $x_0,\dotso, x_n$.
\par
От \ref{e2.4} следва, че
\[
L_{n+1}(f;t) = L_n(f;t) +f[x_0, \dotso, x_n, x](t-x_0)\dotso(t-x_n).
\]
\par
Това равенство е вярно за всяко $t$. Специално при $t=x$ имаме
\[
L_{n+1}(f;x) = L_n(f;x) + f[x_0, \dotso, x_n, x](x-x_0)\dotso(x-x_n).
\]
\par
Но тъй като $x$ е интерполационнен възел на $L_{n+1}(f;t)$, то $L_{n+1}(f;t) = f(x)$. Следователно
\begin{equation}\label{e2.6}
f(x) = L_n(f,x) +f[x_0,\dotso, x_n,x](x-x_0)\dotso(x-x_n).
\end{equation}
\par
Равенството беше изведено при предположение, че $x\not\in(x_0, \dotso, x_n)$. При $x=x_k,k=0,\dotso, n$ по дефиниция имаме $f(x) = L_n(f;x)$.
\par
Да отбележим, че \ref{e2.6} е в сила за всяка функция $f$ определена в точките $x_0, \dotso, x_n,x$.
\par
Да сравним сега формулата \ref{e2.6} с известната ни вече формула 
\[
f(x) = L_n(f;x) + \frac{f^{(n+1)}(\xi)}{(n+1)!}(x-x_0)\dotso(x-x_n),
\]
изведена при предположение, че $f$ има непрекъната $(n+1)$-ва производна. В първия случай остатъка при интерполиране с $L_n(f;x)$ е записан като
\[
f[x_0, \dotso, x_n,x]w(x),\hspace{12pt}w(x) = (x-x_0)\dotso(x-x_n),
\]
а във втория като
\[
\frac{f^{(n+1)}(\xi)}{(n+1)!}w(x),
\]
където $\xi$ е някаква точка. Следователно разделената разлика на $f$ в $n+2$ точки $x_0, \dotso,x_n,x$ е равна на $(n+1)$-вата производна в някаква междинна точка $\xi$.
\begin{feature}\label{c2.2}
Нека $f(x)$ има непрекъсната производна до $k$-тата включително в интервала $[a,b]$ и $x_0,\dotso,x_n$ са произволни различни точки в $[a,b]$. Тогава 
\begin{equation}\label{e2.7}
f[x_0,\dotso,x_k] = \frac{f^(k)(\xi)}{k!},
\end{equation}
където $\xi$ е някаква точка от интервала $[min\{x_0,\dotso, x_k\}, max\{x_0,\dotso,x_k\}]$. 
\end{feature}
\par
От тази връзка директно следва, че ако $f\in\pi_{n-1}$, то $f[x_0,\dotso,x_k] = 0$, защото $f^(k)(t)\equiv 0$
\par
Схемата за пресмятане на разделени разлики се представя по следния начин
\begin{itemize}
    \item в $I^{\text{вия}}$ стълб - $x_i$ възлите
    \item в $II^{\text{рия}}$ стълб - стойностите $\{f(x)\}$. 
\end{itemize}
Коефициентите $f[x_0,\dotso,x_k], k=0,\dotso, n$ във формулата на Нютон се намират по горния диагонал на таблицата.
\begin{center}
\textit{\underline{Схема за пресмятане на разделени разлики}}
\begin{tabular}{|c c c c c|}
\hline
$x_i$&$f_i$&$f[.,.]$&$f[.,.,.]$&$f[.,.,.,.]$\\
\hline
$x_0$   &   $f(x_0)$&               &                 &\\
        &           & $f[x_0,x_1]$  &                 &\\
$x_1$   &   $f(x_1)$&               &$f[x_0,x_1,x_2]$ &\\
        &           & $f[x_1,x_2]$  &                 &$f[x_0,x_1,x_2,x_3]$\\
$x_2$   &$f(x_2)$   &               &$f[x_1,x_2,x_3]$ & \\
        &           & $f[x_2,x_3]$  &                 &$f[x_1,x_2,x_3,x_4]$\\
$x_3$   &$f(x_3)$   &               &$f[x_2,x_3,x_4]$ &\\
        &           & $f[x_3,x_4]$  &                 &\\
$x_4$   &$f(x_4)$   &               &                 &\\   
\hline
\end{tabular}
\end{center}
\newpage
\section{Средноквадратични приближения}
\begin{definition}
Едно линейно пространство $H$ се нарича хилбертово, ако в него е въведено скаларно произведение. Това значи, че за всеки два елемента $f,g \in H$ се съпоставя число $(f,g)$, което удовлетворява исловията:
\begin{enumerate}
    \item $(f,f)\leq 0$, като $(f,f) = 0 \iff f=0$ ,
    \item $(f,g) = (g,f)$,
    \item $(\alpha f +\beta g, h) = \alpha (f,h) + \beta(g,h)$
\end{enumerate}    
\end{definition}
\begin{definition}
Всяко хилбертово пространство може да се нормира, като се въведе норма по следния начин:
\begin{equation}\label{e3.1}
||f|| = \sqrt{(f,f)}.
\end{equation}
\end{definition}
\begin{definition}
Нормата \ref{e3.1} поражда разстоянието
\[
d(f,g) = ||f-g|| = \sqrt{(f-g,f-g)}
\]
\end{definition}
\begin{definition}
Нека $[a,b]$ е даден интервал, краен или безкраен и функцията $\mu$ е определена и неотрицателна в $[a,b]$. Да предположин още, че
\[
\int_a^b\mu(x)dx > 0
\]
за всеки подинтервана $[\alpha, \beta] $ на $[a,b]$. Всяка функция $\mu(x)$ с тези свойства се нарича теглова функция или тегло в $[a,b]$
\end{definition}
\begin{definition}
Нека $[a,b]$ е даден интервал и нека $\mu$ е интегруема теглова функция в $[a,b]$. Да означим с $\mathcal{L}_2[a,b]$ пространството от всички функции опрефелин в $[a,b]$, за които
\[
\int_a^b \mu(x)f^2(x)dx < \infty.
\]
\end{definition}
Ясно е, че $\mathcal{L}_2[a,b]$ е линейно пространство.
\begin{definition}
Нека в $\mathcal{L}_2[a,b]$ е въведо скаларно произведение по следния начин:
\[
(f,g) = \int_a^b\mu(x)f(x)g(x)dx.
\]
\end{definition}
\par
Лесно се вижда, че това определение наистина удовлетворява условията за скаларно произведение. Така $\mathcal{L}_2[a,b]$ става хилбертово пространство.
\begin{definition}
Нормата
\[
||f|| = \left\{\int_a^b\mu(x)f^2(x)dx\right\}_\frac{1}{2}
\]
се нарича средноквадратична норма. Тя поражда средноквадратично разстояние
\[
\rho(f,g) = \left\{\int_a^b\mu(x)(f(x)-g(x))^2dx\right\}^\frac{1}{2}.
\]
\begin{definition}
Нека $\varphi_0(x),\dotso, \varphi_n(x)$ са произволно линейно независими функции от пространството $\mathcal{L}_2[a,b]$. В частност, $\{\varphi_i\}$ могат да бъдат например алгебричните полиноми $1, x, x^2, \dotso, x^n$. Тогава в $\mathcal{L}_2[a,b]$ можем да разглеждаме задачата за средноквадратично приближение на дадена функция $f\in\mathcal{L}_2[a,b]$ с обобщени полиноми $a_0\varphi_0(x)+a_1\varphi_1(x)+\dotso + a_n\varphi_n(x)$.
\end{definition}
\end{definition}
Съгласно общата теория на приближения в хилбертово пространство е в сила следната теорема.
\begin{theorem}\label{T3.1}
За всяка функция $f$ от $\mathcal{L}_2[a,b]$ съществува единствен полином 
\[
p(x) = \displaystyle\sum_{k=0}^na_k\varphi_k(x),
\]
за който в 
\[
\int_a^b\mu(x)|f(x)-p(x)|^2dx = \underset{a_k}{min}\int_a^b\mu(x)
                                \left[f(x) - \displaystyle\sum_{k=0}^na_k\varphi_k(x)\right]^2dx
\]
При това, ако $\varphi_0,\dotso,-\varphi_n$ е ортогонална система, то
\begin{equation}\label{e3.2}
p(x) = \displaystyle\sum_{k=0}^n\int_a^b\mu(t)f(t)\varphi_k(t)dt.\varphi_k(x)
\end{equation}
\end{theorem}
\paragraph{Метод на най-малките кввадрати}
\par
На практика често се сблъскваме със следната задача.
\par
От теоретични съображения е известно, че изследваната от нас функция $f$ е от определен вид зависещ от $n $ параметри $a_1,\dotso,a_n$.(Например $\displaystyle\sum_{k=1}^na_kx^{k-1}, \displaystyle\prod_{k=1}^n\sin(a_kx),\displaystyle\sum_{k=1}^na_kx$ и тн.) Можем да изчислим стойността на $f$ с определена точност с определен брой точки. При това, намирането на стойността на $f$ в дадена точка може да бъде свързана с провеждане на скъпоструващ експеримент. Целта е да възстановим приближено параметрите $a_1, \dotso, a_n$ с възможено най-голяма точност въз основа на информацията
\[
f(x_1),f(x_2),\dotso,f(x_m), m>n.
\]
Най-често тези числа са приближения на истинската стоност на $f$.
\par
Например, нека знаем, че зависимостта $y=f(x)$, която изследваме е линейна, тоест
\[
f(x) = Ax+B
\]
при някакви $A$ и $B$. Разполагаме с експирементално получени стойности на $f(x):f_i = f(x_i), i = 1,\dotso,m$. Те са представени по долу на фиг. 7.


\begin{tikzpicture}
\begin{axis}[
    xlabel = {фиг. 7},
    xtick =      {1    ,1.1,1.5,2,1.8  ,2.3,2.5,3},
    xticklabels = {$x_1$,   ,   , ,$x_i$,   ,   ,$x_m$},
    ymajorgrids=true,
    grid style=dashed
]
 
\addplot[
    only marks,
    color=blue,
    mark=square,
    ]
    coordinates {
    (1,1)(1.2,1.1)(1.5,1.3)(2,2)(1.8,2.1)(2.3,2.2)(2.5,2.8)(3,3)
    };
 \addplot[
    color = red,
    domain = 0:4
    ]
    {
        x
    };
\end{axis}
\end{tikzpicture}
\par
Поради неточността на измерването или несъвършенството на експеримента точките $(x_i,f_i), i=1,\dotso,m$ явно не лежат на една права. Знаем, че функцията $f(x)$ е линейна. Тогава коя права да вземем за представител на получените данни? Има много кандидати за такъв представител. Например, бихме могли да вземем произволни две точки $(x_i, f_i)$ и $(x_j, f_j)$ от таблицата о за приближение на $f$ да вземем правата $l$ през тези две точки. Това е един случаен избор да се опитаме да подходим по-теоретично. Търсим функция от вида $f(x) = Ax+B$. Да означим с $d_i$ отклонението на експериментално получената стойност $f_i$ в точката $x_i$ от предлаганата стойност чрез $l$, тоест
\[
d_i = f_i - (Ax_i + B), i=1,\dotso,m.
\]
\par
Съществуват няколко разумни подхода за избора на параметрите $A$ и $B$ на $l$.
\par
1) Избираме $A$ и $B$ така, че да минимизираме величината
\[
\underset{1\leq i \leq m}{max}|d_i|.
\]
\par
По този начин се стараем да направим максималното разстояние между $f$ и $l$ в точките $x_1,\dotso, x_m$ минимално. Такъв критерий е приемлив, но неговата реализация е трудна, тъй като води до репаването на една нелинейна задача(функцията $max|di|$ е нелинейна спрямо $A$ и $B$).
2) Избираме $A$ и $B$ така, че да минимизира величината 
\[
\displaystyle\sum_{i=1}^m|d_i|.
\]
\par
Възраженията срещу критерия 1) остават и в този случай. Те се възприемали твърде сериозно в миналото, когато хората не са разполагали със средства за бързо смятане. Затова може би изборът е паднал на следващия критерийй, който води до линейна система за определяне на параметрите.
3) Избираме $A$ и $B$ така, че да минимизират 
\[
S(A,B)  \displaystyle\sum_{i=1}^md_i^2
\]
\par
В този случай 
\[
S(A,B) = \displaystyle\sum_{i=1}^m|f_i - (Ax_i +B)|^2
\]
и необходмите условия за минимум(които са и достатъчни) водят до системата
\begin{align*}
\frac{\partial S}{\partial A} &= 0 &\Rightarrow\hspace{12pt}
                                \displaystyle\sum_{i=1}^m(f_i - (Ax_i+B))x_i &=0\\
\frac{\partial S}{\partial B} &= 0 &\Rightarrow\hspace{12pt}
                                \displaystyle\sum_{i=1}^m(f_i - (Ax_i+B)) &=0
\end{align*}
\par
Този подход за определяне на неизвестни параметри на функцията по таблица от данни се нарича метод на най-малките квадрати. Да го представим в една по-обща форма.
\par
Нека $\{F(x,a_1,\dotso, a_n)\}$ е фамилия от функции, която се описва от параметрите $a_i\in I_i, i=1,\dotso, n$. Нека $f_1,\dotso, f_m$ са стойностите на конкретна функция от тази фамилия.
\begin{definition}
Ще казваме, че $F(x,a_1,\dotso,a_n)$ е приближение на данните $f_1,\dotso, f_m$ по метода на най-малките квадрати, ако $a_1,\dotso, a_n$ минимизира израза
\[
\displaystyle\sum_{i=1}^m\mu_i[F(x_i, a_1,\dotso, a_n)-f_i]^2,
\]
където $\{\mu_i\}_1^m$ са предварително зададени числа(наречени тегла).
\end{definition}
\par
Да разгледаме една конкретна ситуация - приближаване на функция с алгебрични полиноми от степен $n$ в множеството от точки $x_1<\dotso<x_m (m>n)$. И така, искаме да намерим приближение
\[
p(x) = a_0+a_1x+\dotso+a_nx^n
\]
на $f$ по метода на най-малките квадрати, въз основа на стойностите $f_i = f(x_i), i = 1, \dotso, m$. Нека $\{\mu_i\}_1^m$ са дадени тегла. Тогава съгласно казаното по-горе $a_0, a_1,\dotso,a_n$ се определят така, че да минимизират израза
\[
\Phi(a_0,\dotso,a_n) = \displaystyle\sum_{i=1}^m\mu_i[f_i - \displaystyle\sum_{i=1}^na_kx_i^k]^2
\]
\par
Вижда се, че $\Phi^{\frac{1}{2}}(a_0,\dotso,a_n)$ е всъщност разстоянието между $f$ и $p$ в хилбертово пространство $H_\Delta$ от функции, определени в $x_1,\dotso,x_n$ снабдени със скаларно произведение
\[
(f,g) = \displaystyle\sum_{i=1}^m\mu_if(x_i)g(x_i).
\]
\par
Това скаларно произведение поражда нормата
\[
||f|| = \left\{\displaystyle\sum_{i=1}^m\mu_if^2(x_i)\right\}^1/2,
\]
която от своя страна поражда разстоянието
\[
\rho(f,g) = \left\{\displaystyle\sum_{i=1}^m\mu_i[f(x_i)-g(x_i)]^2\right\}^1/2.
\]
\par
В тези термини, нашата функция $\{\Phi(a_0,\dotso,a_n\}$ е точка равна на разстоянието между $f$ и $p$. Следователно методът на най-малките квадрати води до задачата за най-добро приближение с алгебрични в хилбертово пространство $H_\Delta$. От общата теория следва, че решението $a_0,\dotso,a_n$ се определя от линейната система (4), което в този случай приема вида
\[
\displaystyle\sum_{i=1}^m\mu_i[a_0x_i^k+a_1x_i^{k+1}+\dotso+a_nx_i{k+n}] = 
\displaystyle\sum_{i=1}^m\mu_if(x_i)^k,\hspace{12pt}k = 0,\dotso,n.
\]
\par
За да избегнем решаването на тази система можем да изберем предварително подходящ базис в пространството $\pi_n$ от алгебрични полиноми. Например, ако търсехме полином $p$ от вида
\[
p(x) = b_0P_0(x)+\dotso+b_nP_n(x),
\]
където полиномите $\{P_k(x)\}$ образуват ортогонална система в множеството от точки $x_1,\dotso, x_m$ с тегла $\{\mu_i\}$, то горната система щеше да се редуцира до една диагонална система
\[
b_k\displaystyle\sum_{i=1}^m\mu_iP_k^2(x_i) = 
\displaystyle\sum_{i=1}^m\mu_iP_k(x_i)f(x_i),
\]
откъдето коефициентът $b_k$ се определя веднага.
\newpage
\section{Интерполационни квадратурни формули}
Определеният интеграл е основно математическо понятие. Редица величини се представят чрез определен интеграл. Затова много често на практика възниква необходимостта от численото пресмятане на определени интеграли.
\par
Известно е от курса по анализ, че един определен интеграл $I(f)=\int_a^bf(x)dx$ може да бъде пресметнат точно само когато подинтегралната функция е достатъчно проста. В общия случай числото $I(f)$, което се определя като граница на числова редица, е недостъпно за математика въоръжен с молив, лист и курса по анализ. Съществуват обаче редица числени методи, които позволяват определения интеграл да бъде пресметнат с дадена точност. Тук ще разгледаме някои от тези методи.
\par
Просто правило за приближено смятане на интеграли може да се получи, като заменим подинтегралната функция $f(x)$ с нейния полином на Лагранж.
\par
Да предположим, че са известни стойностите на $f(x)$ в точките $x_0,\dotso,x_n$.Съгласно формулата на Нютон
\begin{equation}\label{e4.1}
f(x) = L_n(f;x)+f[x_0,\dotso,x_n,x]w(x),
\end{equation}
където $L_n(f;x)$ е интерполационния полином на Лагранж
\[
L_n(f;x) = \displaystyle\sum_{k=0}^nf(x_k)l_k(x),
\]
а $w(x) = (x-x_0)\dotso(x-x_n)$. Като интегрираме \ref{e4.1} почленно от $a$ до $b$ получаваме формулата
\begin{equation}\label{e4.2}
I(f) = \displaystyle\sum_{k=0}^nc_kf(x_k),
\end{equation}
където
\begin{equation}\label{e4.3}
c_k = I(l_k)=\int_a^b\displaystyle\prod_{i=0,i\neq k}^n\frac{x-x_i}{x_k-x_i}dx, k=0,\dotso,n.
\end{equation}
\par
Грешката на това приближение е :
\begin{equation}\label{e4.4}
R(f) = I(f)-I(L_n(f;x)) = \int_a^bf[x_0,\dotso,x_n,x]w(x)dx
\end{equation}
\par
Формула за приближение, в която определеният интеграл се приближава с линейна комбинация на стойностите на подинтегралната функция или нейни производни в краен брой точки, се нарича квадратурна формула. \ref{e4.2} е една квадратурна формула. Точките $x_0,\dotso, x_n$ са възли, а числата $c_0,\dotso,c_n$ - коефициент на квадратурната формула.
\begin{definition}
Една квадратурна фирмула от вида \ref{e4.2} се нарича интерполационна, ако нейните коефициенти $c_k$ се получават по формула \ref{e4.3}.
\end{definition}
\par
С други думи, формула с $n+1$ възела се нарича интерполационна квадратурна формула, ако тя се получава чрез интегриране на интерполационния полином на Лагранж със същите възли.
\par
\begin{definition}\label{d4.2}
Ще казваме, че формула \ref{e4.2} е точна за $f$, ако $R(f) = 0$.
\end{definition}
\begin{theorem}\label{T4.1}
Ако квадратурната формула \ref{e4.2} е интерполационна, то тя е точна за всеки полином от класа $\pi_n$. Обратно, ако една формула от вида \ref{e4.2} е точна за всички полиноми от класа $\pi_n$, то тя е интерполационна.
\end{theorem}
\begin{proof}
($\Rightarrow$)\hspace{12pt}Нека \ref{e4.2} е интерполационна квадратурна формула и $f\in\pi_n$. Тогава $f(x)=L_n(f;x)$ и следователно $R(f) = 0$, тоест формулата е точна (по дефиниция \ref{d4.2}).
($\Leftarrow$)\hspace{12pt}Да допуснем, че \ref{e4.2} е точна за всички полиноми $f\in\pi_n$. Тогава тя ще бъде точна и за полиномите $l_i(x)$. Следователно
\[
I(l_i) = \displaystyle\sum_{k=0}^nc_kl_i(x_k)=c_i,\hspace{12pt}i=0,\dotso,n,
\]
защото $l_i(x_k)=\delta_{ik}$. Получихме \ref{e4.3}.
\par
Теоремата е доказана.
\end{proof}
\par
Както вече видяхме, грешката на интерполационната квадратурна формула се дава с израза \ref{e4.4}. Тази формула не е удобна за приложение, тъй като грешката се изразява отново чрез интеграз, който дори е по-сложен от предишния. Въз основа на \ref{e4.4} обаче се правят оценки, които се използват на практика. Ще разгледаме два случая, в които се изразът за грешката може да се запише в по прост вид.
\par
Нека полиномът $w(x)$ не си сменя знака в $(a,b)$. Да предположим още, че $f(x)$ има непрекъсната $(n+1)$-ва производна в $[a,b]$. Тогава $f[x_0,\dotso,x_n,x]$ е непрекъсната функция на $x$ в $[a,b]$ и съгласно теоремата за средните стойности съществува точка $t\in(a,b):$
\[
R(f)  = f[x_0,\dotso,x_n,t]\int_a^bw(x)dx
\]
По нататък, от връзката между разделената разлика и производната следва, че $\exists\xi\in[a,b]:$
\begin{equation}\label{e4.5}
R(f) = \frac{f^{(n+1)(\xi)}}{(n+1)!}\int_a^bw(x)dx
\end{equation}
\par
Ако $w(x)$ си сменя знака само един път в $[a,b]$ и $\int_a^bw(x)=0$, то изразът \ref{e4.4} също може да се опрости. В този случай използваме рекурентната връзка
\[
f[x_0,\dotso,x_{n+1},x] = \frac{f[x_0,\dotso,x_n,x]-f[x_0,\dotso,x_{n+1}]}{x-x_{n+1}},
\]
за да получим
\[
f[x_0,\dotso,x_n,x] = f[x_0,\dotso,x_n,x_{n+1},x](x-x_{n+1})+f[x_0,\dotso,x_{n+1}],
\]
за всяка точка $x_{n+1}$ от $[a,b]$. Следователно
\begin{align*}
R(f) &= \int_a^bf[x_0,\dotso,x_{n+1},x](x-x_{n+1})dx+f[x_0,\dotso,x_{n+1}]\int_a^bw(x)dx =\\&=\int_a^bf[x_0,\dotso,x_{n+1},x](x-x_{n+1})w(x)dx.
\end{align*}
В последното равенство използваме условието,че $\int_a^bw(x)dx=0$. Да предположим сега, че $x_{n+1}$ е точката, в която $w(x)$ си сменя знака. Тогава функцията $(x-x_n+1)w(x)$ ще има постоянен знак в $[a.b]$. По нататък, при предположение, че $f$ има непрекъсната производна, заключаваме въз основа на теоремата за средните стойности, че $\exists\xi\in(a,b):$
\begin{equation}\label{e4.6}
R(f) = \frac{f^{(n+2)(\xi)}}{(n+2)!}\int_a^b(x-x_{n+1})w(x)dx.
\end{equation}
\par
Да отбележим, че в този случай грешката се изразява, чрез $(n+2)$-та производна. Следователно $R(f)=0\forall f\in\pi_{n+1}$, тоест квадратурната формула е точна за всички полиноми дори и от $(n+1)$-ва степен.
\par
Използването на интерполационен полином за приближено пресмятане на интеграли е било предложено от Нютон. Английският инжинер Коутс е пресметна коефициентите на интерполационните квадратурни формули в $[0,1]$ в случая на равно отдалечени възли $x_k=\frac{k}{n}, k=0,\dotso,n$ за $n=1,\dotso,15$ и публокувал таблицата с тези коефициенти. Затова интерполационните квадратурни формули с равноотдалечени възли се наричат формули на Нютон-Коутс.
\par
Сега ще изведем в явен вид някои елементарни квадратурни формули.
\par
\underline{\textbf{Нека $n=0$}}.Тогава
\[
L_0(f;x) = f(x_0)
\]
и следователно
\[
I(f)\approx I(L_0)=f(x_0)(b-a).
\]
Специално при $x_0=\frac{a+b}{2}$ получаваме
\begin{equation}\label{e4.7}
\int_a^bf(x)dx = f\left(\frac{a+b}{2}\right)(b-a).
\end{equation}
\par
В този случай функцията $w(x)=x-\frac{a+b}{2}$ си сменя знака в точката $x=\frac{a+b}{2}$ и $\int_a^bw(x)dx=0$.
\par
Следователно при $x_0=x_1=\frac{a+b}{2}$ полиномът $(x-x_0)(x-x_1) = (x-\frac{a+b}{2})^2$ ще има постоянен знак в $[a,b]$. Тогава съгласно \ref{e4.6}
\begin{equation}\label{e4.8}
R(f) = \frac{f^{''}(\xi)}{2!}\int_a^b(x-x_0)^2dx=f^{''}(\xi)\frac{(b-a)^3}{24}.
\end{equation}
\begin{center}
\begin{tikzpicture}
\begin{axis}[
    xlabel = {фиг. 4.7.},
    ymin=0,
    xmin=-1, xmax=2,
    domain=-0.2:1.5,
    xtick={0,0.7,1.4},
    xticklabels={$a$,$\frac{a+b}{2}$,$b$}
]
% The function
\addplot [very thick, cyan!75!blue] {-x^4+x^3+2} node [anchor=west] {$f$};
\draw[draw=black, fill = blue, fill opacity = 0.05] (100,0) rectangle(170,210.29);
\draw[draw=black, fill = blue, fill opacity = 0.05] (170,0) rectangle(240,210.29);
\addplot[pattern=north east lines,  domain=0:1.4 ,samples=100] {-x^4+x^3+2} \closedcycle;
\end{axis}
\end{tikzpicture}
\end{center}
\par
Формула \ref{e4.7} е известна като квадратурна формула на правоъгълниците. Тя има прост геометричен смисъл (фиг.4.7.). Интегралът $I(f)$, който е равен на лицето на фигурата, определена от графиката на $f$, се приближава с лицето на правоъгълника с основа $[a,b]$ и височина $f\left(\frac{a+b}{2}\right)$. Оттук идва и наименованието на тази формула.
\par
\textbf{\underline{Нека $n=1$}}. Да изберем $x_0=a,x_1=b$. Тогава
\begin{align*}
L_1(f;x)&=f(a)+f[a,b](x-a)\\
f(x)&=L_1(f;x)+f[a,b,x](x-a)(x-b)
\end{align*}
\par
Заменяме $I(f)$ с $I(L_1)$ и получаваме квадратурна формула-
\begin{equation}\label{e4.9}
\int_a^bf(x)dx\approx\frac{b-a}{2}[f(a)-f(b)].
\end{equation}
\par
За определяне на грешката ще се възползваме от \ref{e4.5}, тъй като в този случай полиномът $w(x) = (x-a)(x-b)$ има постоянен знак в $(a,b)$. Имаме
\[
R(f) = \frac{f^{''}(\xi)}{2}\int_a^b(x-a)(x-b)dx.
\]
Пресмятаме интеграла и получаваме
\begin{equation}\label{e4.10}
R(f) = -\frac{f^{''}(\xi)}{12}(b-a)^3.
\end{equation}
\par
Формула \ref{e4.9} се нарича квадратурна формула на трапеците. Нейният геометричен смисъл е показан на фиг.4.9.
\begin{center}
\begin{tikzpicture}
\begin{axis}[
    xlabel = {фиг. 4.9.},
    ymin=0,
    xmin=-1, xmax=2,
    domain=-0.2:1.5,
    xtick={0,1.4},
    xticklabels={$a$, $b$}
]
% The function
\addplot [very thick, cyan!75!blue] {-x^4+x^3+2} node [anchor=west] {$f$};
\draw[fill=blue, fill opacity = 0.5] (100,0) -- (100,200) -- (240,90.24) -- (240,0) -- cycle;
\addplot[pattern=north east lines,  domain=0:1.4 ,samples=100] {-x^4+x^3+2} \closedcycle;
\end{axis}
\end{tikzpicture}
\end{center}
\par
Сега да разгледаме една интерполационна квадратурна формула с три равноотдалечени възли.
\par
\underline{\textbf{Нека $n=2$}}. Имаме
\[
f(x)=L_2(f;x)+f[x_0,x_1,x_2,x](x-x_0)(x-x_1)(x-x_2).
\]
Оттук получаваме формулата
\begin{equation}\label{e4.11}
I(f)\approx I(L_2).
\end{equation}
\par
Да изберем $x_0=a,x_1=\frac{a+b}{2},x_2=b$. В този случай функцията $w(x)=(x-a)\left(x-\frac{a+b}{2}\right)(x-b)$ си сменя знака в $(a,b)$ само в точката $x_1 = \frac{a+b}{2}$. Освен това $\int_a^bw(x)dx=0$. Следователно остатъчния член се представя като в \ref{e4.6}. Имаме
\[
R(f) = \frac{f^{IV}(\xi)}{4!}\int_a^b(x-a)\left(x-\frac{a+b}{2}\right)^2(x-b)dx
\]
Пресмятаме интеграла и получаваме окончателно
\begin{equation}\label{e4.12}
R(f) = -\frac{f^{IV}(\xi)}{2880}(b-a)^5.
\end{equation}
\par
За да получим явния вид на квадратурната формула \ref{e4.11} бихме могли да запишем $L_2(f;x)$  по формулата на Нютон и да пресметнем $I(L_2)$. Ние ще покажем тук един по-прост начин. Да означим за удобство с $p(x)$ интерполационния полином $L_2(f;x)$. По формулата на правоъгълниците \ref{e4.7} и по трапеците \ref{e4.9}, съответно:
\begin{align*}
I(p)&=p\left(\frac{a+b}{2}\right)(b-a)+\frac{p^{''}(\xi_1)}{24}(b-a)^3\\
I(p)&=\frac{b-a}{2}[p(a)+p(b)]-\frac{p^{''}(\xi_2)}{12}(b-a)^3,
\end{align*}
където $\xi_1,\xi_2$ са някакви точки в $(a,b)$. Но $p\in\pi_2$. Следователно $p^{''}(t)$ е константа за всяко $t$. Оттук $p^{''}(\xi_1) = p^{''}(\xi_2)$. Тогава да умножим второто уравнение с $\frac{1}{2}$ и да го прибавим към първото.
Получаваме
\[
I(p)+\frac{1}{2}I(p) = p\left(\frac{a+b}{2}\right)(b-a) + \frac{b-a}{4}[p(a)+p(b)].
\]
\par
Тъй като полиномът $p(x)$ интерполира $f(x)$ в точките $a,\frac{a+b}{2},b$, то от горното равенство следва, че
\begin{equation}\label{e4.13}
I(p) = \frac{b-a}{6}\left[f(a)+4f\left(\frac{a+b}{2}\right)+f(b)\right].
\end{equation}
Получихме формулата
\begin{equation}\label{e4.14}
\int_a^bf(x)dx \approx \frac{b-a}{6}\left[f(a)+4f\left(\frac{a+b}{2}\right)+f(b)\right]
\end{equation}
\par
Това е знаменитата квадратурна формула на Симпсън. От израза за грешката и \ref{e4.12} се вижда, че тя е точна за всички полиноми от степен по-малка или равна на $3$.
\par
Изведените дотук квадратурни формули( на правоъгъкниците, на трапеците и на Симпсън) се наричат елементарни квадратурни формули. В този си вид те рядко се използват,з защото грешката при тяхното приложение е голяма, особено, ако интервалът на интегриране $[a,b]$ е голям. Това се вижда от изразите \ref{e4.8},\ref{e4.10} и \ref{e4.12} за грешките. На практика обикновено се постъпва по следния начин. Интервалът $[a,b]$ се разделя на $m$ равни части с помощта на точките $x_0,\dotso, x_m$. След това във всеки подинтервал $[x_i,x_{i+1}]$ се прилага някоя от елементарните квадратурни формули за пресмятане на интеграла $\int_a^bf(x)dx$ и получените изрази се сумират. В резултат на което се получават така наречената съставна квадратурна формула. Ние тук ще изведем и съставните формули в явен вид, защото те имат голямо приложение.
\begin{center}
\textbf{Съставна квадратурна формула на правоъгълниците}
\end{center}
\par
Нека $x_i = a+ih, i=0,\dotso,m, h=\frac{b-a}{m}$. По формулата за правоъгълниците имаме
\[
\int_{x_i}^{x_{i+1}}f(x)dx = f\left(\frac{x_i+x_{i+1}}{2}\right)(x_{i+1} - x_i) + \frac{f''(\xi)}{24}h^3,
\]
където $\xi_i\in(x_i,x_{i+1}).$
\par
Сумираме горните равенства за $i=0,\dotso,m$ и получаваме квадратурната формула
\[
\int_a^bf(x)dx = \frac{b-a}{m}\displaystyle\sum_{i=0}^{m}f\left(\frac{x_i+x_{i+1}}{2}\right)
\]
с грешка
\[
R(f) = \frac{(b-a)^3}{24m^2}\frac{1}{m}\displaystyle\sum_{i=0}^mf''(\xi_i).
\]
Но числото $\frac{1}{m}[f''(\xi_0)+\dotso+f''(\xi_m)]$ е средно аритметично на $m$ стойности на $f''(x)$ в $[a,b]$.Следователно то се намира между точната долна и точната горна граница на $f''(x)$ в $[a,b]$. Оттук следва, че $\exists\xi\in[a,b]:$
\[
\frac{1}{m}[f^{''}(\xi_1)+\dotso+f^{''}(\xi_m)] = f^{''}(\xi).
\]
Тогава за грешката на съставната квадратурна формула на правоъгълниците получаваме
\[
R(f) = \frac{(b-a)^3}{24m^2}f^{''}(\xi).
\]
\par
Сега вече се вижда, че с помощта на съставната формула можем да пресметнем интеграла $I(f)$ с каквато точност искаме стига да изберем достатъчно голямо $m$.
\begin{center}
\textbf{Съставна квадратурна формула на трапеците}
\end{center}
\par
Напълно аналогично, като използваме формулата на трапеците \ref{e4.9} получаваме:
\begin{align*}
\int_a^bf(x)dx &\approx \frac{b-a}{2m}[f_0+2f_1+\dotso+2f_{m-1}+f_m]=\\&=\frac{b-a}{2m}[f_0+2\displaystyle\sum_{i=1}^{m-1}f_i+f_m]\\
R(f)&=-\frac{(b-a)^3}{12m^3}f''(\xi), \xi\in[a,b].
\end{align*}
Тук за краткост сме записали $f_i$ вместо $f(x_i)$.
\begin{center}
\textbf{Съставна квадратурна формула на Симпсън}
\end{center}
\par
В този случай разделяме $[a,b]$ на четен брой подинтервали $[x_{i-1},x_i], i=1,\dotso,2m$ и след това прилагам формулата на Симпсън за двойния подинтервал $[x_{i-1},x_{i+1}],i=1,3,\dotso,2m-1$. Получаваме
\begin{align*}
\int_a^bf(x)dx &\approx \frac{b-a}{6m}[f_0+f_{2m}+2(f_2+f_4+\dotso+f_{2m-2})+4(f_1+f_3+\dotso+f_{2m-1})]=\\&=\frac{b-a}{6m}[f_0+2\displaystyle\sum_{i=1}^{m-1}f_{2m}+4\displaystyle\sum_{i=1}^{m}f_{2i-1}+f_{2m}]\\
R(f) &= -\frac{(b-a)^5}{2880m^4}f^{IV}(\xi), \xi\in[a,b].
\end{align*}
\newpage
\section{Итерационни методи за решаване на линейни системи}
\par
Приближените методи за решаване на линейни системи са главно итерационни. При тях се избира подходящо начално приближение $x_0 = \{x_1^0,\dotso, x_n^0\}$ на решението $\bar{x} = (x_1, \dotso, x_n)$ и след това на формула от вида
\[
\bar{x}_{k+1} = B_k\bar{x}_k+\bar{d}_k,\hspace{12pt}k=0,1,2,\dotso
\]
се строи редица $\{\bar{x}_k\}$ от точки в $\mathbb{R}^n$, която клони към решението $\bar{x}$.
\par
Тук ние ще разгледаме някои основни итерационни методи за решаване на линейни системи.
\begin{center}
\textbf{Метод на простата итерация}
\end{center}
\par
Нека е дадена система $A\bar{x}=\bar{b}$. Преобразуваме я с помощта на неособената матрица $C$ в еквивалентна на нея система :
\[
x = \bar{x}-C\{A\bar{x} - \bar{b}\}.
\]
Построяваме итерационния процес
\[
\bar{x}_{k+1} = \bar{x}_k-C\{A\bar{x}_k-\bar{b}\},\hspace{12pt} k = 0,1,2,\dotso
\]
При някакво начално приближение $\bar{x}_0$. Горната формула може да се запише още така
\[
\bar{x}_{k+1}=(E-CA)\bar{x}_k +C\bar{b}=B\bar{x}_k+\bar{d}.
\]
\begin{theorem}\label{th5.1}
Итерационния процес
\[
\bar{x}_{k+1}=B\bar{x}_k+\bar{d}
\]
е сходящ при произволен избор на начално приближение $\bar{x}_0\iff$ всички собствени стойности на матрицата $B$ са по модул по-малки от $1$.
\end{theorem}
\begin{proof}
Имаме
\begin{align*}
\bar{x}_{k+1}&=B\bar{x}_k + \bar{d}=BB\bar{x}_{k-1}+B\bar{d}+\bar{d}=\dotso=\\
&=B^{k+1}x_0+(B^k+B^{k-1}+\dotso+E)\bar{d}
\end{align*}
\par
При направените предположения за $B$, редът в скобите е сходящ.От това,че матричния геометричен ред $B^k+B^{k-1}+\dotso+E$ е сходящ следва, че$B^{k+1}\rightarrow 0$. Следователно редицата $\{\bar{x}_k\}$ има граница при $k\rightarrow\infty$ и тази граница е $(E-B)^{-1}\bar{d}$. Вижда се, че тази граница е решение на уравнението $\bar{x}=B\bar{x}+\bar{d}$(\textbf{???}),тоест решение на нашата система. Да забележим, че ако редът $E+B+\dotso$ не е сходящ, то и редицата $\{\bar{x}_k\}$ може да бъде разходяща, например при $x_0=\bar{o}$. Теоремата е доказана.
\end{proof}
\begin{corollary}\label{c5.1}
Ако $||B||<1$ за някоя норма $||.||$, то итерационния процес е сходящ при призволно начално приближение $\bar{x}_0$.
\end{corollary}
\par
Твърдението следва веднага от теоремата, като се вземе в предвис, че всяка норма на матрицата е по-голяма по абсолютна стойност от всяка нейна собствена стойност. В този случай дори може да се изведе лесно в една оценка на грешката. Наистина имаме
\[
||\bar{x}_k-\bar{x}||=||B\bar{x}_{k-1}-B\bar{x}\leq ||B||||\bar{x}_{k-1}-\bar{x}||,
\]
откъдето следва
\[
||\bar{x}_k-\bar{x}||\leq||B||^k||\bar{x}_0-\bar{x}||.
\]
Следователно при $||B||<1$ скоростта на сходимост е както при геометрична прогресия.
\par
При итерационни формули от вида
\begin{equation}\label{e5.1}
\bar{x}_{k+1}=(E-CA)\bar{x}_k+C\bar{b} %maj nagore e druga
\end{equation}
критериите за сходимост могат да се наложат направо на матрицата $A=\{a_{ij}\}$. Да разгледаме специалния случай на \ref{e5.1}, когато $C$ е диагонална матрица с елементи по диагонала $\frac{1}{a_n}$,
\[
C=diag\left\{\frac{1}{a_{11}},\dotso,\frac{1}{a_{nn}}\right\}=diag\{a_{11},\dotso,a_{nn}\}^{-1}.
\]
В този случай системата $A\bar{x}=\bar{b}$ се преобразува по стандартния начин - от $i$-тото уравнения се определя $x_i:$
\begin{align*}
\begin{split}
x_i=-\frac{a_{i1}}{a_{ii}}x_1 &-\dotso-\frac{a_{ii-1}}{a_{ii}}x_{i-1}-\frac{a_{ii+1}}{a_{ii}}x_{i+1}-\\&-\dotso-\frac{a_{in}}{a_{ii}}x_n+\frac{b_i}{a_{ii}},\hspace{30pt}i=1,\dotso,n
\end{split}
\end{align*}
и формулите \ref{e5.1} за пресмятане на следващите приближения $x_i^{(k+1)},\dotso x_n^{(k+1)}$ добиват вида
\begin{equation}\label{e5.2}
x_i^{(k+1)} = -\displaystyle\sum_{j=1,j\neq i}^n\frac{a_{ij}}{a_{ii}}x_j^{(k)}+\frac{b_i}{a_{ii}},\hspace{30pt}i=1,\dotso,n.
\end{equation}
\par
Този метод е известен като метод на простата итерация.
\par
Да видим как изглеждат достатъчните условия за сходимост на простата итерация, които произлизат от следствието \ref{c5.1}, при използване на нормата
\[
||B||_w = \underset{1\leq i\leq n}{max}\displaystyle\sum_{j=1}^n|b_{ij}|.
\]
\par
В нашия случай $B=E-CA$. Нека $\{b_{ij}\},\{c_{ij}\},\{\delta_{ij}\}$ са съответно елементите на $B,C$ и $E$. Тогава
\begin{align*}
b_{ij}&=\delta_{ij}-c_{i1}a_{1j} - \dotso -c_{in}a_{nj}=\\&=\delta_{ij}-\frac{1}{a_{ii}}a_{ij}
\end{align*}
и следователно
\begin{align*}
||B||_\infty = \underset{1\leq i\leq n}{max}\displaystyle\sum_{j=1}^n|b_{ij}|=
\underset{1\leq i\leq n}{max}\displaystyle\sum_{j=1}^{n}\left|\delta_{ij}-\frac{a_{ij}}{a_{ii}}\right|=\\&=\underset{1\leq i\leq n}{max}\frac{1}{|a_{ii}|}\displaystyle\sum_{j=1,j\neq i}^n|a_{ij}|
\end{align*}
\par
Оттук се вижда, че условието $||B||_\infty<1$ се записва като
\[
\displaystyle\sum_{j=1,j\neq i}^n|a_{ij}|<a_{ii},\hspace{30pt}i=1,\dotso,n.
\]
\par
Това всъщност е условието $A$ да бъде матрица с доминиращ главен диагонал.
\par
Аналогично, условието
\[
||B||_1=\underset{1\leq i\leq n}\displaystyle\sum_{i=1}^n|b_{ij}|<1
\]
се свежда към
\[
\displaystyle\sum_{i=j}^n\left|\frac{a_{ij}}{a_{ii}}\right|<1,\hspace{30pt}j=1,\dotso,n.
\]
\begin{center}
\textbf{Метод на Зайдел}
\end{center}
\par
На практика често се използва една естествена модификация на метода на простата итерация, наречена метод на Зайдел. При нея в поредното $i$-то уравнение от \ref{e5.2} за определяне на $x_i^{(k+1)}$ се използват изчислените вече $(k+1)$-ви приближения на $x_1,\dotso,x_{i-1}$. По този начин се получават формулите
\[
x_i^{(k+1)} = -\displaystyle\sum_{j=1}^{i-1}\frac{a_{ij}}{a_{ii}}x_j^{(k+1)}
              -\displaystyle\sum_{j=i+1}^n\frac{a_{ij}}{a_{ii}}x_j^{(k)}
              +\frac{b_i}{a_{ii}}\hspace{20pt},i=1,\dotso,n.
\]
\begin{theorem}\label{t5.2}
Методът на Зайдел е сходящ при произволно начално приближение $\bar{x_0}\iff$ всички корени на уравнението
\[
det\left|\begin{array}{cccc}
\lambda a_{11}&a_{12}&\dotso&a_{1n}\\
\lambda a_{21}&\lambda a_{22}&\dotso&a_{2n}\\
\dotso&\dotso&\dotso&\dotso\\
\lambda a_{n1}&\lambda a_{n2}&\dotso&\lambda a_{nn}

\end{array}\right|=0
\]
са по модул по-малки от $1$.
\end{theorem}
\begin{proof}
Да представим $A$ като $A=U+V$, където $U$ е долна триъгълна матрица, включваща главния диагонал, а $V$ е горна триъгълна матрица с нулеви елементи по главния диагонал и под него. Тогава системата $A\bar{x}=\bar{b}$ се записва във вида:
\[
U\bar{x}=-V\bar{x}+\bar{b}
\]
и метода на Зайдел се представя чрез итерационния процес
\[
U\bar{x}_{k+1}=-V\bar{x}_k+\bar{b}.
\]
Решаваме относно $\bar{x}_{k+1}$ и получаваме
\begin{equation}\label{e5.3}
\bar{x}_{k+1}=-U^{-1}V\bar{x}_k+U^{-1}\bar{b}.
\end{equation}
\par
Но това е изчислителен процес от типа на метода на простата итерация, който беше разгледан в теорема \ref{th5.1}. Съгласно тазо теорема методът \ref{e5.3} е сходящ $\iff$ собствените стойности на матрицата $-U^{-1}V$ са по модул по-малки от $1$. тоест когато корените на уравнението
\[
det|-U^{-1}V-\lambda E|=-det|\lambda E + U^{-1}V|=0,
\]
което е еквивалентно(като умножим с $detU$) на 
\[
det|\lambda U + V|=0,
\]
са по модул по-малки от $1$. Теоремата е доказана.
\end{proof}
\begin{center}
\textbf{Сравняване на метода на Зайдел и метода на простата итерация}
\end{center}
\par
Областите на сходимост на простата итерация и метода на Зайдел се пресичат. Не е трудно да се покаже, че и методът на Зайдел е сходящ за системата $A\bar{x}=\bar{b}$, когато матрицата $A$ е с доминиращ главен диагонал. По долу ще покажем, че в този случах методът на Зайдел е по-бързо сходящ(в известен смисъл) от метода на простата итерация.
\begin{theorem}\label{th5.3}
Ако матрицата $A$ има доминиращ главен диагонал , то метода на Зайдел е по-бързо сходящ от метода на простата итерация.
\end{theorem}
\begin{proof}
Това търдение трябва да се разбира в следния смисъл. Ще намерим еднотипни оценки за скоростта на сходимост на метода на простата итерация и на метода на Зайдел и ще покажем, че оценката при метода на Зайдел е по-добра от тази при метода на простата итерация.
\par
Ще използваме векторната норма $||\bar{x}||_\infty=\underset{1\leq i\leq n}{max}|x_i|$ и съответната съгласувана метрична норма $||.||_\infty$.
\par
Нека $A=\{a_{ij}\}$ е произволна матрица с доминиращ главен диагонал, тоест
\[
\displaystyle\sum_{j=1,j\neq i}^n|a_{ij}|<|a_{ii}|, \hspace{30pt}i=1,\dotso,n.
\]
Означаваме
\begin{align*}
c_{ij}&=-\frac{a_{ij}}{a_{ii}}\\
d_i&=\frac{b_i}{a_{ii}}\\
\mu &= \underset{i\leq i\leq n}{max}\frac{\displaystyle\sum_{j=1}^n|a_{ij}|}{|a_{ii}|}=\underset{1\leq i\leq n}{max}\displaystyle\sum_{j=1,j\neq i}^n|c_{ij}|
\end{align*}
\par
Да отбележим, че съгласно нашето предположение за $A, \mu<1$. На простата итерация съответства схемата
\[
x_i^{(k+1)} = \displaystyle\sum_{j=1,j\neq i}^nc_{ij}x_j^{(k)}+d_i,
\]
а на метода на Зайдел
\[
x_i^{(k+1)}=\displaystyle\sum_{j=1}^{i-1}c_{ij}x_j^{(k+1)}+
            \displaystyle\sum_{i+1}^nc_{ij}x_j^{(k)}+d_{i}.
\]
\par
Нека $\bar{x}$ е решението на системата. Имаме
\[
x_i=\displaystyle\sum_{j=1,j\neq i}^nc_{ij}x_j+d_i.
\]
\par
За грешката по метода на простата итерация получаваме
\begin{align*}
\begin{split}
||\bar{x}-\bar{x}_{k+1}||_infty&
    \leq \underset{1\leq i\leq n}\displaystyle\sum_{j=1,j\neq i}^n|c_{ij}||x_j^{(k)}-x_j|\leq\\&
    \leq\mu||\bar{x}_k-\bar{x}||_\infty\leq\dotso\leq\\&
    \leq\mu^{k+1}||\bar{x}_0-\bar{x}||_\infty
\end{split}
\end{align*} 
\par
Да въведем още означения
\begin{align*}
\beta_i&=\displaystyle\sum_{j=1}^{i-1}|c_{ij}|\\
\gamma_i&=\displaystyle\sum_{j=i+1}^n|c_{ij}|\\
\nu&=\underset{i}{max}\frac{\gamma_i}{1-\beta_i}.
\end{align*}
\par
За метода на Зайдел имаме
\begin{align*}
\begin{split}
||\bar{x}-\bar{x}_{k+1}||_\infty
    &\leq\underset{1\leq i\leq n}{max}|x_i-x_i^{(k+1)}\leq\\&
    \leq\underset{i}{max}\left\{\displaystyle\sum_{j=1}^{i-1}|c_{ij}||x_j^{(k+1)}-x_j|+\displaystyle\sum_{j=i+1}^n|c_{ij}||x_j^{(k)}-x_j|\right\}\leq\\&
    \leq\underset{i}{max}\{\beta_{i_0}||\bar{x}_{k+1}-\bar{x}||_\infty+\gamma_{i_0}||\bar{x}_k-\bar{x}||_\infty\}
\end{split}
\end{align*}
Оттук
\begin{align*}
\begin{split}
||\bar{x}-\bar{x}_{k-1}||_\infty&\leq\frac{\gamma_{i_0}}{1-\beta_{i_0}}||\bar{x}-\bar{x}_k||_\infty\leq\\
                                &\leq\nu||\bar{x}-\bar{x}_k||_\infty\leq\dotso\leq\\
                                &\leq\nu^{k+1}||\bar{x}_0-\bar{x}||_\infty.
\end{split}
\end{align*}
Но $\beta_i+\gamma_i\leq\mu\leq 1.$ Тогава
\begin{align*}
\begin{split}
\beta_i+\gamma_i-\frac{\gamma_i}{1-\beta_i}&=\frac{\beta_i(1-\beta_i)-\gamma_i\beta_i+\gamma_i-\gamma_i}{1-\beta_i}=\\
                                           &=\frac{\beta_i(1-\beta_i-\gamma_i)}{1-\beta_i}\geq 0.
\end{split}
\end{align*}
Следователно
\[
\mu=\underset{i}{max}(\beta_i+\gamma_i)\geq\underset{i}{max}\frac{\gamma_i}{1-\beta_i}=\nu.
\]
\par
И така грешката при метода на Зайдел се оценява с израз, който клони към нула по-бързо от този получен при метода на простата итерация.
\end{proof}

\newpage
\end{document}
